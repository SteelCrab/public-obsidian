# AWS EKS 클러스터 구축

#cicd #eks #kubernetes #helm #kubectl #aws

---

```table-of-contents
```

eksctl → EKS 클러스터 → LB Controller → 앱 배포

---

## 1. AWS EKS 도구 설치

### AWS 사용자 확인
```
aws sts get-caller-igentity
```
### helm 설치 
> [!Note]
> Mac 기준 

```shell
# 패키지 설치
brew install helm

# AWS EKS 공식 Helm 차트 저장소 추가 
helm repo add eks https://aws.github.io/eks-charts

```
![[스크린샷 2026-02-06 오전 10.02.36.png]]

```shell
 helm repo update

```
![[스크린샷 2026-02-06 오전 10.12.14.png]]


## 2. kubectl 설치 
[kubectl 설치](https://kubernetes.io/docs/tasks/tools/install-kubectl-macos/)
#### mac(eks_install.sh)
```shell
#!/bin/bash

# EKS 설치 스크립트 for macOS
# 실행 방법: chmod +x eks_install.sh && ./eks_install.sh

set -e

echo "=================================="
echo "EKS 도구 설치 시작 (macOS)"
echo "=================================="

# 색상 정의
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# 아키텍처 감지
ARCH=$(uname -m)
if [ "$ARCH" = "arm64" ]; then
    echo -e "${GREEN}Apple Silicon 감지됨${NC}"
    KUBECTL_ARCH="arm64"
else
    echo -e "${GREEN}Intel 프로세서 감지됨${NC}"
    KUBECTL_ARCH="amd64"
fi

# Homebrew 설치 확인
if ! command -v brew &> /dev/null; then
    echo -e "${YELLOW}Homebrew가 설치되어 있지 않습니다. 설치 중...${NC}"
    /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
else
    echo -e "${GREEN}✓ Homebrew가 이미 설치되어 있습니다.${NC}"
fi

# 1. kubectl 설치
echo ""
echo "1. kubectl 설치 중..."
if command -v kubectl &> /dev/null; then
    echo -e "${GREEN}✓ kubectl가 이미 설치되어 있습니다. ($(kubectl version --client --short 2>/dev/null || kubectl version --client))${NC}"
else
    brew install kubectl
    echo -e "${GREEN}✓ kubectl 설치 완료${NC}"
fi

# 2. AWS CLI 설치
echo ""
echo "2. AWS CLI 설치 중..."
if command -v aws &> /dev/null; then
    echo -e "${GREEN}✓ AWS CLI가 이미 설치되어 있습니다. ($(aws --version))${NC}"
else
    brew install awscli
    echo -e "${GREEN}✓ AWS CLI 설치 완료${NC}"
fi

# 3. eksctl 설치
echo ""
echo "3. eksctl 설치 중..."
if command -v eksctl &> /dev/null; then
    echo -e "${GREEN}✓ eksctl이 이미 설치되어 있습니다. ($(eksctl version))${NC}"
else
    brew tap weaveworks/tap
    brew install weaveworks/tap/eksctl
    echo -e "${GREEN}✓ eksctl 설치 완료${NC}"
fi

# 4. Helm 설치
echo ""
echo "4. Helm 설치 중..."
if command -v helm &> /dev/null; then
    echo -e "${GREEN}✓ Helm이 이미 설치되어 있습니다. ($(helm version --short))${NC}"
else
    brew install helm
    echo -e "${GREEN}✓ Helm 설치 완료${NC}"
fi

# 5. EKS Helm 차트 저장소 추가
echo ""
echo "5. EKS Helm 차트 저장소 추가 중..."
if helm repo list | grep -q "eks"; then
    echo -e "${YELLOW}EKS 저장소가 이미 추가되어 있습니다. 업데이트 중...${NC}"
    helm repo update eks
else
    helm repo add eks https://aws.github.io/eks-charts
    echo -e "${GREEN}✓ EKS Helm 차트 저장소 추가 완료${NC}"
fi

# 6. Helm 저장소 업데이트
echo ""
echo "6. Helm 저장소 업데이트 중..."
helm repo update
echo -e "${GREEN}✓ Helm 저장소 업데이트 완료${NC}"

# 7. kubectl 자동완성 설정 (선택사항)
echo ""
echo "7. kubectl 자동완성 설정 (선택사항)..."
SHELL_TYPE=$(basename "$SHELL")

if [ "$SHELL_TYPE" = "zsh" ]; then
    if ! grep -q "kubectl completion zsh" ~/.zshrc 2>/dev/null; then
        echo -e "${YELLOW}zsh용 kubectl 자동완성을 설정하시겠습니까? (y/n)${NC}"
        read -r response
        if [ "$response" = "y" ]; then
            echo 'source <(kubectl completion zsh)' >> ~/.zshrc
            echo 'alias k=kubectl' >> ~/.zshrc
            echo 'complete -F __start_kubectl k' >> ~/.zshrc
            echo -e "${GREEN}✓ kubectl 자동완성 설정 완료 (~/.zshrc)${NC}"
            echo -e "${YELLOW}변경사항 적용: source ~/.zshrc${NC}"
        fi
    else
        echo -e "${GREEN}✓ kubectl 자동완성이 이미 설정되어 있습니다.${NC}"
    fi
elif [ "$SHELL_TYPE" = "bash" ]; then
    if ! grep -q "kubectl completion bash" ~/.bash_profile 2>/dev/null; then
        echo -e "${YELLOW}bash용 kubectl 자동완성을 설정하시겠습니까? (y/n)${NC}"
        read -r response
        if [ "$response" = "y" ]; then
            brew install bash-completion@2
            echo 'source <(kubectl completion bash)' >> ~/.bash_profile
            echo 'alias k=kubectl' >> ~/.bash_profile
            echo 'complete -o default -F __start_kubectl k' >> ~/.bash_profile
            echo -e "${GREEN}✓ kubectl 자동완성 설정 완료 (~/.bash_profile)${NC}"
            echo -e "${YELLOW}변경사항 적용: source ~/.bash_profile${NC}"
        fi
    else
        echo -e "${GREEN}✓ kubectl 자동완성이 이미 설정되어 있습니다.${NC}"
    fi
fi

# 설치 확인
echo ""
echo "=================================="
echo "설치 완료 - 버전 확인"
echo "=================================="
echo ""
echo "kubectl version:"
kubectl version --client --short 2>/dev/null || kubectl version --client
echo ""
echo "aws version:"
aws --version
echo ""
echo "eksctl version:"
eksctl version
echo ""
echo "helm version:"
helm version --short
echo ""
echo "helm repos:"
helm repo list
echo ""

# AWS 설정 확인
echo "=================================="
echo "AWS 설정 확인"
echo "=================================="
if aws sts get-caller-identity &> /dev/null; then
    echo -e "${GREEN}✓ AWS 자격 증명이 올바르게 설정되어 있습니다.${NC}"
    aws sts get-caller-identity
else
    echo -e "${YELLOW}⚠ AWS 자격 증명이 설정되어 있지 않습니다.${NC}"
    echo "다음 명령어로 AWS CLI를 설정하세요:"
    echo "  aws configure"
fi

echo ""
echo "=================================="
echo "설치 완료!"
echo "=================================="
echo ""
echo "다음 단계:"
echo "1. AWS 자격 증명 설정 (아직 설정하지 않은 경우):"
echo "   aws configure"
echo ""
echo "2. EKS 클러스터에 연결:"
echo "   aws eks update-kubeconfig --region <region> --name <cluster-name>"
echo ""
echo "3. 클러스터 확인:"
echo "   kubectl cluster-info"
echo "   kubectl get nodes"
echo ""
echo "4. 유용한 Helm 차트:"
echo "   - AWS Load Balancer Controller:"
echo "     helm install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system --set clusterName=<your-cluster>"
echo "   - EBS CSI Driver:"
echo "     helm install aws-ebs-csi-driver eks/aws-ebs-csi-driver -n kube-system"
echo ""


```


#### Linux (eks_install.sh)

> [!Note]
> 반드시 sudo 넣을 것 

```shell
#!/bin/bash

# 1. 패키지 업데이트 및 필수 도구 설치 (unzip, curl, net-tools 포함)
apt-get update -y
apt-get install -y curl unzip net-tools apt-transport-https ca-certificates gnupg lsb-release

# 2. Docker 설치 (공식 저장소 등록 방식)
mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg

echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null

apt-get update -y
apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

# Docker 권한 설정 (접속 계정 ubuntu 기준)
systemctl enable --now docker
usermod -aG docker ubuntu
ln -s /usr/libexec/docker/cli-plugins/docker-compose /usr/local/bin/docker-compose

# 3. AWS CLI v2 설치 (여기서 unzip이 사용됩니다)
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
./aws/install
rm -rf awscliv2.zip aws/

# 4. kubectl 설치 (최신 안정 버전)
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
rm kubectl

# 5. eksctl 설치 (EKS 관리 도구)
curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
mv /tmp/eksctl /usr/local/bin
```


## 3. EKS 설정

### 선행
#### 0. VPC 구축

#### 보안 그룹 생성

> [!Important]
> EKS 클러스터 생성 **전에** 보안 그룹을 먼저 만들어야 한다.
> 클러스터 SG는 자동 생성되지만, 노드 SG와 LB SG는 수동 생성이 필요하다.

| 보안 그룹 | 용도 | 생성 시점 |
|----------|------|----------|
| 클러스터 SG | 컨트롤 플레인 ↔ 노드 | 자동 생성 |
| 노드 SG | 워커 노드 트래픽 | VPC 생성 후, 클러스터 생성 전 |
| LB SG | NLB/ALB 외부 트래픽 | 클러스터 생성 후, 서비스 배포 전 |

##### 노드 보안 그룹 규칙

| 방향 | 포트 | 소스/대상 | 설명 |
|------|------|----------|------|
| Inbound | All | 자기 자신 (SG) | 노드 간 통신 |
| Inbound | All | 클러스터 SG | 컨트롤 플레인 → 노드 |
| Inbound | 80, 8080 | LB SG | LB → Pod |
| Outbound | All | `0.0.0.0/0` | ECR, S3 등 |

##### LB 보안 그룹 규칙

| 방향 | 포트 | 소스/대상 | 설명 |
|------|------|----------|------|
| Inbound | 80 | `0.0.0.0/0` | HTTP |
| Inbound | 443 | `0.0.0.0/0` | HTTPS |
| Outbound | All | `0.0.0.0/0` | 노드로 전달 |

> 상세: [[cicd-deploy-eks]]

### 서브넷 태그 설정 (필수)

> [!Important] 서브넷에 태그를 추가해야 합니다
> AWS Load Balancer Controller가 서브넷을 식별하려면 아래 태그가 필요합니다.

#### 1.퍼블릭 서브넷 태그
```bash
# 각 퍼블릭 서브넷에 추가
aws ec2 create-tags --resources <PUBLIC_SUBNET_A> <PUBLIC_SUBNET_C> <PUBLIC_SUBNET_D> \
  --tags Key=kubernetes.io/role/elb,Value=1 \
         Key=kubernetes.io/cluster/<CLUSTER_NAME>,Value=shared
```

### 2.프라이빗 서브넷 태그
```bash
# 각 프라이빗 서브넷에 추가
aws ec2 create-tags --resources <PRIVATE_SUBNET_A> <PRIVATE_SUBNET_C> <PRIVATE_SUBNET_D> \
  --tags Key=kubernetes.io/role/internal-elb,Value=1 \
         Key=kubernetes.io/cluster/<CLUSTER_NAME>,Value=shared
```

### 설정값 테이블
| 플레이스홀더                  | 타입  | 값   | 설명                   | 예시                      |
| ----------------------- | --- | --- | -------------------- | ----------------------- |
| `pista-cluster`         | 이름  |     | 클러스터 이름              | `my-cluster`            |
| `ap-southeast-1`        | 이름  |     | AWS 리전               | `ap-northeast-2`        |
| `1.31`                  | 버전  |     | 쿠버네티스 버전 (1.29~1.35) | `1.31`                  |
| `vpc-067604da147fbd40a` | ID  |     | VPC ID               | `vpc-0123456789abcdef`  |
| `<PUBLIC_SUBNET_A>`     | ID  |     | 퍼블릭 서브넷 A            | `subnet-0123456789abcd` |
| `<PUBLIC_SUBNET_C>`     | ID  |     | 퍼블릭 서브넷 C            | `subnet-0123456789abcd` |
| `<PUBLIC_SUBNET_D>`     | ID  |     | 퍼블릭 서브넷 D            | `subnet-0123456789abcd` |
| `<PRIVATE_SUBNET_A>`    | ID  |     | 프라이빗 서브넷 A           | `subnet-0123456789abcd` |
| `<PRIVATE_SUBNET_C>`    | ID  |     | 프라이빗 서브넷 C           | `subnet-0123456789abcd` |
| `<PRIVATE_SUBNET_D>`    | ID  |     | 프라이빗 서브넷 D           | `subnet-0123456789abcd` |
| `<NODE_GROUP_NAME>`     | 이름  |     | 노드 그룹 이름             | `my-cluster-ng`         |
| `<INSTANCE_TYPE>`       | 이름  |     | EC2 인스턴스 타입          | `t3.medium`             |
| `<DESIRED_CAPACITY>`    | 숫자  |     | 초기 노드 개수             | `3`                     |
| `<VOLUME_SIZE>`         | 숫자  |     | EBS 볼륨 크기 (GB)       | `20`                    |
| `<NODE_SG_ID>`          | ID  |     | 노드 보안 그룹 (워커 노드용)    | `sg-0123456789abcdef`   |
| `<LB_SG_ID>`            | ID  |     | LB 보안 그룹 (NLB/ALB용)  | `sg-0123456789abcdef`   |

### eksctl 설정 파일 (cluster.yaml) with placeholder
``` yaml
# eksctl 설정 파일 버전 정의
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

# 클러스터 기본 정보 설정
metadata:
  name: <CLUSTER_NAME>
  region: <REGION>
  version: "<K8S_VERSION>"

# 기존 VPC 및 서브넷 활용 설정
vpc:
  id: <VPC_ID>
  # 클러스터 API 서버 접근 제어
  clusterEndpoints:
    publicAccess: true        # 외부에서 kubectl 접근 허용
    privateAccess: true       # VPC 내부에서 kubectl 접근 허용
  # 특정 IP만 퍼블릭 API 서버에 접근 허용 (보안 강화)
  publicAccessCIDRs:
    - "<ALLOWED_IP>/32"
  subnets:
    # 외부 로드밸런서가 위치할 퍼블릭 서브넷 (elb 태그 필요)
    public:
      <REGION>a: { id: <PUBLIC_SUBNET_A> }
      <REGION>c: { id: <PUBLIC_SUBNET_C> }
      <REGION>d: { id: <PUBLIC_SUBNET_D> }
    # 실제 워커 노드가 위치할 프라이빗 서브넷 (internal-elb 태그 필요)
    private:
      <REGION>a: { id: <PRIVATE_SUBNET_A> }
      <REGION>c: { id: <PRIVATE_SUBNET_C> }
      <REGION>d: { id: <PRIVATE_SUBNET_D> }

# 관리형 노드 그룹(Managed Node Group) 설정
managedNodeGroups:
  - name: <NODE_GROUP_NAME>
    instanceType: <INSTANCE_TYPE>
    # minSize: 1                 # 최소 1대 유지
    # maxSize: 3                 # 최대 3대까지 확장 가능
    desiredCapacity: <DESIRED_CAPACITY>
    volumeSize: <VOLUME_SIZE>
    privateNetworking: true
    securityGroups:
      attachIDs: [<NODE_SG_ID>]    # 노드 보안 그룹
    iam:
      withAddonPolicies:
        imageBuilder: true # ECR 이미지 접근 권한
        autoScaler: true # Cluster Autoscaler 권한
        albIngress: true # 로드밸런서 권한
        cloudWatch: true # CloudWatch 로그 권한

# IAM OIDC 프로바이더 설정
iam:
  withOIDC: true
```


### eksctl 설정 파일 (cluster.yaml)
``` yaml
# eksctl 설정 파일 버전 정의
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

# 클러스터 기본 정보 설정
metadata:
  name: pista-cluster
  region: ap-southeast-1
  version: "1.32"

# 기존 VPC 및 서브넷 활용 설정
vpc:
  id: vpc-067604da147fbd40a
  # 클러스터 API 서버 접근 제어
  clusterEndpoints:
    publicAccess: true        # 외부에서 kubectl 접근 허용
    privateAccess: true       # VPC 내부에서 kubectl 접근 허용
  # 특정 IP만 퍼블릭 API 서버에 접근 허용 (보안 강화) - 선택
  #publicAccessCIDRs:
  #  - "<ALLOWED_IP>/32"
  subnets:
    # 외부 로드밸런서가 위치할 퍼블릭 서브넷 (elb 태그 필요)
    public:
      ap-southeast-1a: { id: subnet-0f088b6509fe031b3 }
      ap-southeast-1b: { id: subnet-0c4132c130561f5b6 }
      ap-southeast-1c: { id: subnet-0b027cd2c6bd27b4b }
    # 실제 워커 노드가 위치할 프라이빗 서브넷 (internal-elb 태그 필요)
    private:
      ap-southeast-1a: { id: subnet-02a6f3654c4525250 }
      ap-southeast-1b: { id: subnet-0ff40cb6c629d5200 }
      ap-southeast-1c: { id: subnet-03f3128d159e662d2 }

# 관리형 노드 그룹(Managed Node Group) 설정
managedNodeGroups:
  - name: pista-noge-group
    instanceType: t3.medium
    minSize: 1                 # 최소 1대 유지
    maxSize: 3                 # 최대 3대까지 확장 가능
    desiredCapacity: 3
    volumeSize: 20
    privateNetworking: true
    securityGroups:
      attachIDs: [sg-03c40d9a7665fd3d8]  # 노드 보안 그룹 (<NODE_SG_ID>)
    iam:
      withAddonPolicies:
        imageBuilder: true # ECR 이미지 접근 권한
        autoScaler: true # Cluster Autoscaler 권한
        albIngress: true # 로드밸런서 권한
        cloudWatch: true # CloudWatch 로그 권한
        ebs: true # EBS 불륨 사용 권한 
        certManager: true # SSL/TLS 인증서 자동 발급 권한 
        externalDNS: true # 도메인(Route53) 자동 연결 권한

# IAM OIDC 프로바이더 설정
iam:
  withOIDC: true
```

#### 태그 설명
| 태그 키 | 값 | 대상 | 설명 |
|---------|-----|------|------|
| `kubernetes.io/role/elb` | `1` | 퍼블릭 서브넷 | 외부 로드밸런서용 |
| `kubernetes.io/role/internal-elb` | `1` | 프라이빗 서브넷 | 내부 로드밸런서용 |
| `kubernetes.io/cluster/<CLUSTER_NAME>` | `shared` | 모든 서브넷 | 클러스터 공유 리소스 |

### 관련 명령어
| 명령어                                                                                 | 설명                      |
| ----------------------------------------------------------------------------------- | ----------------------- |
| `eksctl create cluster -f cluster.yaml`                                             | 설정 파일로 클러스터 생성          |
| `eksctl delete cluster -f cluster.yaml`                                             | 클러스터 삭제                 |
| `eksctl get cluster --region <region>`                                              | 클러스터 목록 조회              |
| `eksctl get nodegroup --cluster <cluster-name>`                                     | 노드 그룹 목록 조회             |
| `eksctl scale nodegroup --cluster <cluster-name> --name <nodegroup-name> --nodes 5` | 노드 개수 조정                |
| `aws eks update-kubeconfig --region <region> --name <cluster-name>`                 | kubeconfig 설정 (클러스터 연결) |
| `kubectl get nodes`                                                                 | 노드 상태 확인                |
| `kubectl cluster-info`                                                              | 클러스터 정보 확인              |

> [!Note] OIDC란?
> **OIDC (OpenID Connect)** 는 OAuth 2.0 기반의 인증 프로토콜이다.
>
> EKS에서 OIDC를 활성화하면:
> - **Pod에 IAM 역할 부여 가능** (IRSA: IAM Roles for Service Accounts)
> - 노드 전체가 아닌 **특정 Pod에만** AWS 권한 부여
> - 최소 권한 원칙 적용으로 **보안 강화**
>
> 예: S3 접근이 필요한 Pod에만 S3 권한 부여, 다른 Pod는 접근 불가

## 4. deploy/svc
> [!Note]
> 간단한 nginx svc, deploy구현 

### nginx-web-deploy
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-web
  labels:
    app: nginx-web
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx-web
  template:
    metadata:
      labels:
        app: nginx-web
    spec:
      containers:
        - name: nginx
          image: nginx:1.27
          ports:
            - containerPort: 80
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 200m
              memory: 256Mi

```
### nginx-web-svc
```yaml
apiVersion: v1
kind: Service
metadata:
  name: pista-svc-nginx-web
  annotations: # AWS LoadBalancerController 옵션
	  service.beta.kubernetes.io/aws-load-balancer-type: "external"
	  service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: "instance"
	  service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"
	 service.beta.kubernetes.io/aws-load-balancer-security-groups: ""
	 # 보안그룹을 없을 때 사용 (권장x)
	 service.beta.kubernetes.io/aws-load-balancer-source-ranges: "0.0.0.0/0",
	 
labels:
    app: nginx-web

---

spec:
  type: LoadBalancer
  selector:
    app: pista-lb-nginx-web
  ports:
    - name: http
      port: 80
      targetPort: 80
      protocol: TCP
    - name: presign-port
      protocol: TCP
      port: 8080
      targetPort: 8080
      
```

```
kubectl apply -f deployment.yaml service.yaml
```
## 5. 배포 결과 
```shell
kubectl get deploy,svc
```
![[스크린샷 2026-02-06 오후 12.14.37.png]]

![[스크린샷 2026-02-06 오후 12.15.20.png]]

---


## 6. AWS Load Balancer Controller 설치
###  1. 스크립트  설치 
```shell
#!/bin/bash

set -e

  

CLUSTER_NAME="pista-cluster"

REGION="ap-southeast-1"

ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

POLICY_ARN="arn:aws:iam::$ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy"

  

echo "=== AWS Load Balancer Controller 설치 스크립트 ==="

  

# 1. IAM Policy 생성 (없으면 생성)

echo "1. IAM Policy 확인 및 생성..."

if ! aws iam get-policy --policy-arn $POLICY_ARN >/dev/null 2>&1; then

curl -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.7.2/docs/install/iam_policy.json

aws iam create-policy \

--policy-name AWSLoadBalancerControllerIAMPolicy \

--policy-document file://iam_policy.json

rm iam_policy.json

echo "IAM Policy 생성 완료."

else

echo "IAM Policy가 이미 존재합니다."

fi

  

# 2. ServiceAccount 생성 (IRSA)

echo "2. ServiceAccount 생성..."

eksctl create iamserviceaccount \

--cluster=$CLUSTER_NAME \

--namespace=kube-system \

--name=aws-load-balancer-controller \

--role-name AmazonEKSLoadBalancerControllerRole \

--attach-policy-arn=$POLICY_ARN \

--approve \

--region $REGION \

--override-existing-serviceaccounts

  

# 3. Helm 설치

echo "3. Helm Chart 설치..."

helm repo add eks https://aws.github.io/eks-charts

helm repo update

helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \

-n kube-system \

--set clusterName=$CLUSTER_NAME \

--set serviceAccount.create=false \

--set serviceAccount.name=aws-load-balancer-controller

  

echo "=== 설치 완료 ==="

kubectl get deployment -n kube-system aws-load-balancer-controller

```

### 2. **설치 확인:**

```bash

kubectl get deployment -n kube-system aws-load-balancer-controller

```
### 3.결과
![[스크린샷 2026-02-06 오후 4.00.20 1.png]]

---

## GitHub Secrets (EKS 배포 준비)

> [!Note]
> 이 날은 EKS 클러스터 구축 및 LB Controller 설치까지만 진행.
> 아래 시크릿은 이후 EKS CI/CD 파이프라인 구축 시 ([[CICD_2026-02-09]]) 설정한다.

| 시크릿 | 설명 | 설정 시점 |
|--------|------|----------|
| `AWS_ACCESS_KEY_ID` | IAM 액세스 키 | 기존 |
| `AWS_SECRET_ACCESS_KEY` | IAM 시크릿 키 | 기존 |
| `AWS_REGION` | AWS 리전 | 기존 |
| `ECR_REPOSITORY_FASTAPI_APP` | FastAPI ECR 레포 | 02-09 추가 |
| `ECR_REPOSITORY_NGINX_WEB` | Nginx ECR 레포 | 02-09 추가 |
| `ARGOCD_SERVER` | ArgoCD Server 주소 | 02-09 추가 |
| `ARGOCD_PASSWORD` | ArgoCD admin 비밀번호 | 02-09 추가 |

> 상세: [[cicd-deploy-eks]]

---

## 관련 노트

- [[CICD_2026-02-05]] - 이전: S3 + ASG 배포
- [[CICD_2026-02-09]] - 다음: EKS Nginx + FastAPI + ArgoCD 배포
- [[Kubectl_MOC]] - kubectl 명령어 MOC
- [[k8s-service-loadbalancer]] - LoadBalancer Service